{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5de7accc",
   "metadata": {},
   "source": [
    "# 02a - Fine-tune DistilBERT for Sequence Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "960a0547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "from src import data, models, metrics\n",
    "\n",
    "DATA_DIR = 'data/'\n",
    "OUTPUT_DIR = 'output/distilbert/'\n",
    "MODEL_NAME = 'distilbert_monitors_3epoch'\n",
    "CLASSES = ['Monitor', 'Tv', 'Noise']\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dc6281",
   "metadata": {},
   "source": [
    "## Create DistilBERT Model with Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4183d8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# create model and load pre-trained checkpoint\n",
    "net = models.DistilBERT(pretrained_checkpoint='distilbert-base-uncased', classes=CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f28e509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 66,955,779\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of trainable parameters: {net.num_trainable_params():,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e86c50",
   "metadata": {},
   "source": [
    "## Example of Classification\n",
    "\n",
    "Classify one example to verify that the code executes without errors. The output distribution is uniform as the pre-trained model was not fine-tuned on the given task yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d08f9fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Monitor': 0.33961165, 'Tv': 0.29880092, 'Noise': 0.36158744}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = '32 inch curved screen 144hz monitor 1k 2k 4k fhd ips curved lcd pc hd-mi power vga cable'\n",
    "net.predict_sample(x, return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6244aec1",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b893e933",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-3d875e4c7602e5a9\n",
      "Reusing dataset csv (/home/ec2-user/.cache/huggingface/datasets/csv/default-3d875e4c7602e5a9/0.0.0/e138af468cb14e747fb46a19c787ffcfa5170c821476d20d5304287ce12bbc23)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e1cde170c3640e3b0def3c159fa82a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3898b671ebb4705a1ca416b3452241f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['inp', 'trg', 'metadata'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['inp', 'trg', 'metadata'],\n",
       "        num_rows: 12000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load datasets\n",
    "datasets = load_dataset('csv', data_files={\n",
    "    'train': DATA_DIR + 'monitors_classification_202107_train.csv',\n",
    "    'validation': DATA_DIR + 'monitors_classification_202107_val.csv',\n",
    "    # 'test': DATA_DIR + 'monitors_classification_202107_test.csv'\n",
    "})\n",
    "\n",
    "# tokenize datasets\n",
    "tokenized_datasets = net.tokenize_dataset(datasets)\n",
    "\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d1a91b",
   "metadata": {},
   "source": [
    "## Fine-tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0283734d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'inp', 'input_ids', 'labels', 'metadata', 'trg'],\n",
       "    num_rows: 36000\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#idx = np.random.choice(len(tokenized_datasets['train']), size=36_000, replace=False)\n",
    "#np.save('idx.npy', idx)\n",
    "idx = np.load('idx.npy')\n",
    "traindataset_sample = tokenized_datasets['train'].select(idx)\n",
    "traindataset_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "245dd44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create trainer instance\n",
    "trainer = net.get_trainer(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    eval_dataset=tokenized_datasets['validation'],\n",
    "    no_epochs=3,\n",
    "    bs=32,\n",
    "    gradient_accumulation_steps=2,\n",
    "    lr=0.0001,\n",
    "    wd=0.01,\n",
    "    lr_scheduler_type='linear',\n",
    "    fp16=False,\n",
    "    compute_metrics_cb=metrics.ClassificationMetricsCallback(),\n",
    "    log_level='error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28a7ab90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5625' max='5625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5625/5625 1:19:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.077077</td>\n",
       "      <td>0.978083</td>\n",
       "      <td>0.971114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.051100</td>\n",
       "      <td>0.059294</td>\n",
       "      <td>0.984250</td>\n",
       "      <td>0.979348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.026700</td>\n",
       "      <td>0.059236</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.980310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the network\n",
    "training_output = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e184b916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBERT(distilbert-base-uncased)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save fine-tuned checkpoint\n",
    "net.save_pretrained(OUTPUT_DIR + MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4667ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
